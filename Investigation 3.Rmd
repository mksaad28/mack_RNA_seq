---
title: "Investigation 3"
author: "Michael, Nico, Archana, Benji, Ishan, Niki"
date: "Febuary 2023"
output: html_document
---

# Investigation Goal:

What receptors are upregulated during growth and can we find ligands to aid in 
serum-free media (SFM) development?

--\> Differential expression between proliferation/serum-starvation

--\> Regular expression to identify receptors upregulated in proliferation

--\> Literature and vendor search for ligands to hit the receptors \
      and thus test in SFM

# Collect and process reference gene and ontology information

The following R chunk processes genomic and proteomic data from different 
sources using various packages. The code reads in a fasta file containing CDS 
accessions and gene IDs, and an eggnog-mapper excel file. The gene IDs are 
extracted from the fasta file and matched with the eggnog-mapper annotations 
using left join, and the resulting data is processed to get gene ontologies, 
KEGG categories, and BRITE functional hierarchies. The code uses various 
packages, including limma, tidyverse, clusterProfiler, readxl, and edgeR.

```{r Collect and process reference gene and ontology information}
# Be sure to set the right wd
source("api.R")
library(limma)
library(tidyverse)
library(clusterProfiler)
library(readxl)
library(edgeR)

#' Necessary argument from orthology because neither tuna or mackerel genomes
#' are in handy databases like ensembl, gene ontology, or kegg. First we read 
#' the cds from GCF_910596095.1 and extract the cds accession and the gene id.
#' This is necessary because the cds from GCF_910596095.1 were fed into
#' eggnogg-mapper. This file was downloaded from NCBI genomes.
a <- readLines("data/michael_saad/GCF_910596095.1/cds_from_genomic.accessions_only.fna")

query_to_gene <- tibble()
for (line in a) {
  if (!str_starts(line, ">")) next
  line_split <- str_split(line, " ")[[1]]
  accession <- str_remove(line_split[1], ">")
  # print(accession)
  # print(line_split[2])
  if (!str_detect(line_split[2], "gene")) stop("Missing gene in second field")
  gene <- line_split[2] |>
    str_remove(fixed("[gene=")) |>
    str_remove(fixed("]"))
  query_to_gene <- bind_rows(query_to_gene, bind_cols(query = accession, 
                                                      gene_id = gene))
  # print("--")
}

#' Then we read the eggnogg mapper excel file resulting from querying it with
#' GCF_910596095.1/cds_from_genomic.fna and the default settings on
#' http://eggnog-mapper.embl.de
eggnogg <- readxl::read_xlsx("data/michael_saad/MM_8hli8sc6.emapper.annotations.xlsx", 
                             skip = 2) |>
  left_join(query_to_gene, by = "query") |>
  select(gene_id, everything()) |>
  group_by(gene_id) |>
  slice_head(n = 1)
#' this is a little rough, taking only the first representative per gene when
#' there are multiple transcripts/proteins in the cds dataset.

# Break the eggnogg results into long format
genes_and_brite <- eggnogg |>
  select(gene_id, BRITE) |>
  rename(brite = BRITE) |>
  rowwise() |>
  mutate(brite = str_split(brite, ",")) |>
  unnest(cols = c(brite))

term_to_brite <- genes_and_brite[c('brite','gene_id')]

# get gene ontologies out of eggnogg.
term_to_gene <- eggnogg |>
  select(gene_id, GOs) |>
  filter(GOs != "-") |>
  separate_rows(GOs, sep = ",") |>
  rename(GO = GOs) |>
  select(GO, gene_id)

# kegg categories from yanky br08902 file.
kegg_categories <- jsonlite::read_json("data/br08902.json") |>
  unlist() |>
  as_tibble() |>
  separate(value, into = c("brite", NA), remove = FALSE, extra = "drop") |>
  mutate(brite = str_replace(brite, "Protein", NA_character_)) |>
  rename(category = value)
```

# Data wrangling and processing of gene expression data

The following R chunk performs various data wrangling tasks on gene expression 
data in order to prepare it for downstream analysis. The script reads in two 
files containing gene and expression data respectively, and then proceeds to 
clean and transform the data in several ways.

```{r Data wrangling and processing of gene expression data}
#' Read in the gene expression data from a TSV file, select the Symbol and 
#' description columns, remove any duplicates, group by gene symbol, 
#' concatenate the descriptions for each gene into a single string, 
#' and rename the Symbol column to gene_id.
gene_lookup <- read_tsv("data/michael_saad/gene_result.txt", 
                        col_types = cols(GeneID = col_character()),
                        guess_max = 10^10) |>
              select(Symbol, description) |>
              unique() |>
              group_by(`Symbol`) |>
              summarize(
                description = paste(description, collapse = ";"),
                .groups = "drop") |>
  # Assure a 1:1 mapping even when there are multiple entries for 1 ensembl ID
              rename(gene_id = Symbol)

#' Group the gene lookup data by gene ID and count the number of entries for 
#' each gene, and filter out genes that have more than one entry.
gene_lookup |>
  group_by(gene_id) |>
  summarize(n = n()) |>
  filter(n != 1)

#' # Read in the gene expression data from a TSV file, skip the first row, 
#' select all columns except Chr, Start, End, Strand, and Length, rename the 
#' Geneid column to gene_id, pivot the data from wide to long format, and 
#' remove the "STAR2/output/" and "Aligned.sortedByCoord.out.bam" strings 
#' from the sample column.
expr_long <- read_tsv("data/michael_saad/featurecounts_results.txt", skip = 1) |>
  select(-Chr, -Start, -End, -Strand, -Length) |>
  rename(gene_id = Geneid) |>
  pivot_longer(-gene_id, names_to = "sample", values_to = "count") |>
  mutate(sample = str_remove(sample, "STAR2/output/") |> 
           str_remove("Aligned.sortedByCoord.out.bam"))

#' Select the unique samples from the gene expression data, separate the sample
#' column into the passage and protocol_replicate columns, extract the protocol 
#' and replicate numbers from the protocol_replicate column, and remove the 
#' protocol_replicate column. Filter to only have 
#' proliferation (p) and serum-starved (s) conditions.
sample_lookup <- expr_long |>
  select(sample) |>
  unique() |>
  separate(sample, into = c("passage", "protocol_replicate"), remove = FALSE) |>
  mutate(
    protocol = str_sub(protocol_replicate, 1, 1),
    replicate = str_sub(protocol_replicate, 2, 2)
    ) |>
  select(-protocol_replicate) |>
  filter(protocol %in% c("p", "s"))

#' Group the gene expression data by gene ID, calculate the proportion of 
#' samples with count 0 for each gene, and create a histogram 
#' of the proportion values.
expr_long |>
  group_by(gene_id) |>
  summarize(prop_count0 = mean(count == 0)) |>
  ggplot() +
  aes(x = prop_count0) +
  geom_histogram(binwidth = 0.1)

#' Group the gene expression data by gene ID, add a column for the proportion 
#' of samples with count 0 for each gene, filter out genes where the proportion 
#' is always 1, remove the additional column, and ungroup the data.
expr_clean <- expr_long |>
  group_by(gene_id) |>
  mutate(gene_prop_count0 = mean(count == 0)) |>
  filter(gene_prop_count0 != 1) |>
  select(-gene_prop_count0) |>
  ungroup() ## ^^ Get rid of the genes which are always 0.

# Pivot the gene expression data from long to wide format, with one column 
# for each sample.
expr_wide <- expr_clean |>
  pivot_wider(names_from = sample, values_from = count)

# Calculate counts per million (CPM) for each sample and gene.
expr_wide_cpm <- expr_wide |>
  select(-gene_id) |>
  cpm() |>
  as_tibble() |>
  mutate(gene_id = expr_wide$gene_id) # counts per million

# Convert the CPM data back to long format.
expr_long_cpm <- expr_wide_cpm |>
  pivot_longer(-gene_id,
    names_to = "sample",
    values_to = "cpm"
  )

# Merge in the metadata information (passage, protocol, replicate) 
# for each sample.
# NOTE THAT THIS TABLE IS NEVER ACTUALLY USED
expr_withmeta <- expr_clean |>
  left_join(sample_lookup, by = "sample")

## Run CalcNormFactors and compare cpm to that without normalization 
## --> conclusion, normalization doesn't change much

# Creates a DGEList object from the input data in expr_wide
expr_wide_DGE <- expr_wide |>
    select(-gene_id) |> DGEList()

# Normalize DGE data
expr_wide_DGE_norm <- calcNormFactors(expr_wide_DGE)

# calculates CPM values from the normalized DGE data
expr_wide_norm_cpm <- expr_wide_DGE_norm$counts |>
    cpm() |>
    as_tibble() |>
    mutate(gene_id = expr_wide$gene_id) # counts per million

# Convert DGE data from wide to long format
expr_long_norm_cpm <- expr_wide_norm_cpm |>
    pivot_longer(-gene_id,
                 names_to = "sample",
                 values_to = "cpm"
    )

# Create data frame comparing normalized and unnormalized CPM values
expr_long_comp_norm <- data.frame(
    wo_norm = expr_long_cpm$cpm,
    with_norm = expr_long_norm_cpm$cpm
)

# Perform linear regression on CPM values
linear_model_comp_norm <- lm(wo_norm ~ with_norm, data = expr_long_comp_norm)
summary(linear_model_comp_norm)

# Create scatter plot of CPM values
plot( expr_long_comp_norm$wo_norm, expr_long_comp_norm$with_norm )
abline( linear_model_comp_norm)
```

# PCA

This R chunk performs a principal component analysis (PCA) on a wide-format 
gene expression matrix called "expr_wide", excluding the gene IDs. The resulting
PCA object is then used to predict the PC scores for each sample, which are 
organized into a tibble (a type of data frame) with the sample names as row 
names. The PC scores for the first two principal components (PC1 and PC2) are 
then selected and joined with a separate data frame called "sample_lookup" using
a left join. Finally, the resulting data frame is plotted using ggplot2, with 
PC1 on the x-axis, PC2 on the y-axis, and samples colored and shaped according 
to their passage and protocol, respectively.

```{r PCA}
pca <- prcomp(expr_wide |> select(-gene_id) |> t() |> cpm())

pca_expr <- predict(pca) |>
  as_tibble(rownames = "sample") |>
  select(sample, PC1, PC2) |>
  left_join(sample_lookup)

pca_expr |>
  ggplot() +
  aes(x = PC1, y = PC2, col = passage, shape = protocol) +
  geom_point()
```

# Function for differential gene expression analysis, gene ontology analysis, and KEGG pathway analysis

This R chunk defines a function called "do_medium_analysis" that takes two 
arguments: a filename and a reference passage. Within the function, a design 
matrix is generated using the "model.matrix" function in R, which is used for 
differential expression analysis of gene expression data. The function then 
filters the genes that have sufficiently large counts to be retained in a 
statistical analysis, transforms count data to log2-counts per million (logCPM),
and fits a linear model for each gene given a series of arrays. The function 
then computes moderated t-statistics, moderated F-statistic, and log-odds of 
differential expression by empirical Bayes moderation of the standard errors 
towards a global value. Finally, the function performs gene ontology analysis 
and KEGG pathway analysis, writes the results to csv files, 
and returns no output.

```{r Analysis Function}

#' This performs performs differential gene expression analysis, 
#' gene ontology analysis, and KEGG pathway analysis using RNA-Seq data.
#'
#' @param filename A character string representing the filename to be used for 
#'                  output files.
#'                            
#' @param reference_passage A character string representing the reference 
#'                          passage to use in the analysis.
#'                            
#' @param combo A boolean value indicating whether the analysis of p against s 
#'              should be performed with or without the non-reference passage 
#'              as a conditional.
#'                            
#' @return Doesn't return anything, but it outputs three csv files:
#' df_<filename>_genes.csv
#' df_<filenam>e_pathways.csv 
#' df_<filename>_kegg.csv
#' 
do_medium_analysis <- function(filename, reference_passage, combo = FALSE) {
  #' Generate an interaction design matrix with main effects of passage and 
  #' protocol, as well as their interaction.
  #' 
  #' This design matrix is used for differential expression analysis of 
  #' gene expression data.
  #' 
  #' This is done using the 'model.matrix' function in R.
  #'   - The 'sample_lookup' data frame is used to map sample IDs to 
  #'      experimental conditions (passage and protocol).
  #'   - The 'mutate' function is used to relevel the 'protocol' and 'passage' 
  #'      factors so that the reference levels match the input.
  
  if (!combo) {
    # Compare p and reference protocol 
    # against s and against non-reference passage
    int_design <- model.matrix(~ passage * protocol,
    data = sample_lookup |>
      mutate(
        protocol = relevel(factor(protocol), "p"),
        passage = relevel(factor(passage), reference_passage)
        )
    )
  }
  
  if (combo) {
    # Compare p against s
    int_design <- model.matrix(~ protocol,
    data = sample_lookup |>
      mutate(
        protocol = relevel(factor(protocol), "p"),
        passage = relevel(factor(passage), reference_passage)
        )
    )
  }

  int_keep <- filterByExpr(expr_wide |> select(-gene_id), int_design)
  # filterByExpr: Determine which genes have sufficiently large counts to be 
  # retained in a statistical analysis.

  int_voomed <- voom(
    expr_wide[int_keep, sample_lookup$sample],
    int_design,
    plot = TRUE
    ) 
  # Michael Explanation:
  # Voom: Transform count data to log2-counts per million (logCPM), 
  # estimate the mean-variance relationship and use this to compute 
  # appropriate observational-level weights. The data are then ready 
  # for linear modelling.

  int_fit <- lmFit(int_voomed, int_design)
  # lmFit: Fit linear model for each gene given a series of arrays

  int_fit_ebayes <- eBayes(int_fit)
  # eBayes: Given a linear model fit from lmFit, compute moderated t-statistics,
  # moderated F-statistic, and log-odds of differential expression by empirical 
  # Bayes moderation of the standard errors towards a global value.

  int_limma_res <- topTable(int_fit_ebayes,
    coef = "protocols",
    genelist = expr_wide |> filter(int_keep) |> select(gene_id),
    number = 20000000,
    confint = TRUE
  ) |>
    as_tibble() |>
    left_join(gene_lookup, by = "gene_id") |>
    mutate(hit_num = row_number())

  # topTable: Extract a table of the top-ranked genes from a linear model fit.

  # Gene ontologies ---------------

  int_enricher_obj <- enricher(
    gene = int_limma_res |> filter(adj.P.Val < 0.05) |> pull(gene_id),
    universe = int_limma_res |> pull(gene_id),
    TERM2GENE = term_to_gene #takes gene ID
  )
  # enricher: A universal enrichment analyzer
  # genes are significant genes, universe is all genes. 
  # Later used for Fisher's exact test?
  
  int_enricher_res <- int_enricher_obj@result |> as_tibble()

  go_lookup <- go2term(int_enricher_res$ID) |>
    as_tibble() |>
    left_join(go2ont(int_enricher_res$ID), by = "go_id") |>
    mutate(Ontology = case_when(
      Ontology == "BP" ~ "Biological Process",
      Ontology == "MF" ~ "Molecular Function",
      Ontology == "CC" ~ "Cellular Component"
    ))

  int_enricher_res_tbl <- int_enricher_res |>
    left_join(go_lookup, by = c("ID" = "go_id")) |>
    rowwise() |>
    mutate(ratio = eval(parse(text = GeneRatio)) / eval(parse(text = BgRatio))) |>
    select(-Description) |>
    select(Term, Ontology, ratio, pvalue, p.adjust, qvalue, everything()) |>
    relocate(geneID, .after = last_col())


  data_long <- expr_long_cpm |>
    left_join(sample_lookup, by = "sample") |>
    left_join(gene_lookup, by = "gene_id") |>
    mutate(gene_name = gene_id)

  
  ## KEGG
  kegg_obj <- enricher(
    gene = int_limma_res |> filter(adj.P.Val < 0.05) |> pull(gene_id),
    universe = int_limma_res |> pull(gene_id),
    TERM2GENE = term_to_brite
  )
  # enricher: A universal enrichment analyzer
  # genes are significant genes, universe is all genes. 
  # Later used for Fisher's exact test?
  
  kegg_res_tbl <- kegg_obj@result |> 
    as_tibble() |>
    inner_join(kegg_categories, by = c("ID" = "brite")) |>
    rowwise() |>
    mutate(ratio = eval(parse(text = GeneRatio)) / eval(parse(text = BgRatio))) |>
    select(-Description) |>
    select(category, ratio, pvalue, p.adjust, qvalue, everything()) |>
    relocate(geneID, .after = last_col())
  
  write.csv(int_limma_res, paste("output/dataframes/df",filename,"genes.csv",
                                 sep = "_"))
  write.csv(int_enricher_res_tbl, paste("output/dataframes/df",filename,
                                        "pathways.csv",sep = "_"))
  write.csv(kegg_res_tbl, paste("output/dataframes/df",filename,"kegg.csv",
                                sep = "_"))
}
```

# do_medium_analysis function calls

This R chunk calls the function do_medium_analysis to generate csv files for 
differential gene expression analysis, gene ontology analysis, and KEGG pathway 
analysis that will be used for data visualizations

```{r do_medium_analysis function calls}
medium_p27 <- do_medium_analysis(filename = "media_p27", 
                                 reference_passage = "p27", 
                                 combo = FALSE)
medium_p77 <- do_medium_analysis(filename = "media_p77", 
                                 reference_passage = "p77", 
                                 combo = FALSE)
medium_combined <- do_medium_analysis(filename = "media_combined", 
                                      reference_passage = "p27", 
                                      combo = TRUE)
```
